{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45a4ded4-8725-46c1-a0c2-c4ed531e8d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This notebook is meant to train a classification model from the Iris dataset and save it to the UC\n",
    "# Dummy comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c7beae74-8e38-40e5-a07a-f8b53bd21541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow=='3.4.0'\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b781b85-5fb9-4af5-8642-f5f3fb3993a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a94d72ec-d6d4-4fd3-9792-cc37870736da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog_name\", \"pedroz_e2edata_dev\")\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c8ec82-ceec-4e6f-bd77-bc1ba02016d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'iris_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c01992c-8f50-4c1a-872d-8840ac2e2d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_table_name = f'{catalog_name}.default.iris_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1ea3d22-39fb-48cb-9023-6f5442449f6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/{model_name}_{catalog_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9183695-cffb-40d6-9377-a10a5285b1e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Create an MLFlow experiment\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ed03c85-3569-48d7-823d-4e73110e36ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If you want to autolog the model, use the following command\n",
    "# Note that some of the auto-logging capabilities were set to false because we are logging some metrics \n",
    "mlflow.autolog(log_input_examples=False,log_model_signatures=False,log_models=False,log_datasets=False,)\n",
    "\n",
    "# Start a training run\n",
    "with mlflow.start_run() as run:\n",
    "    # Load data from Unity Catalog table\n",
    "    df_iris = spark.table(feature_table_name).toPandas()\n",
    "    features = ['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']\n",
    "    target = 'species'\n",
    "\n",
    "    X = df_iris[features]\n",
    "    y = df_iris[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "    # Train the model\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate and log metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, y_train)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name='model',\n",
    "        signature=signature,\n",
    "        input_example=X_train.head()\n",
    "    )\n",
    "\n",
    "    # Log input dataset for lineage\n",
    "    data_source = mlflow.data.load_delta(table_name=feature_table_name)\n",
    "    mlflow.log_input(data_source, context=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e85f8e0-b6a0-49da-863c-f090b655a311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Out of all runs in the experiment, only register the run with the best selected metric\n",
    "# Important note: this logic is optional and totally depends on your processes, so feel free to customize it!\n",
    "# If you want, you can simply register the latest run instead, for example. \n",
    "\n",
    "selected_metric = 'test_accuracy'\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id], order_by=[f\"metrics.{selected_metric} DESC\"], max_results=1)\n",
    "best_run_id = runs[0].info.run_id\n",
    "\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "registered_model = mlflow.register_model(model_uri, f\"{catalog_name}.default.{model_name}\")\n",
    "client.set_registered_model_alias(name=registered_model.name, alias=\"challenger\", version=registered_model.version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5753565242613738,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "model-training",
   "widgets": {
    "catalog_name": {
     "currentValue": "pedroz_e2edata_dev",
     "nuid": "c3deff61-8418-4ca2-ae02-acb938772fc8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "pedroz_e2edata_dev",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "pedroz_e2edata_dev",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
