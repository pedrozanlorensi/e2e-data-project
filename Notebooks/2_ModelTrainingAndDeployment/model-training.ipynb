{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45a4ded4-8725-46c1-a0c2-c4ed531e8d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This notebook is meant to train a classification model from the Iris dataset and save it to the UC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c7beae74-8e38-40e5-a07a-f8b53bd21541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow --upgrade --pre\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b781b85-5fb9-4af5-8642-f5f3fb3993a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a94d72ec-d6d4-4fd3-9792-cc37870736da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog_name\", \"pedroz_e2edata_dev\")\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c8ec82-ceec-4e6f-bd77-bc1ba02016d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'iris_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c01992c-8f50-4c1a-872d-8840ac2e2d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_table_name = f'{catalog_name}.default.iris_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1ea3d22-39fb-48cb-9023-6f5442449f6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/{model_name}_{catalog_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9183695-cffb-40d6-9377-a10a5285b1e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/3571252969788486', creation_time=1754402701666, experiment_id='3571252969788486', last_update_time=1754412791706, lifecycle_stage='active', name='/Users/pedro.zanlorensi@databricks.com/iris_model_pedroz_e2edata_dev', tags={'mlflow.databricks.filesystem.experiment_permissions_check': 'test',\n",
       " 'mlflow.experiment.sourceName': '/Users/pedro.zanlorensi@databricks.com/iris_model_pedroz_e2edata_dev',\n",
       " 'mlflow.experimentKind': 'custom_model_development',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'pedro.zanlorensi@databricks.com',\n",
       " 'mlflow.ownerId': '4529363229261380'}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an MLFlow experiment\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ed03c85-3569-48d7-823d-4e73110e36ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/08 16:57:39 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.1 <= scikit-learn <= 1.7.1, but the installed version is 1.3.0. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "2025/08/08 16:57:40 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/08/08 16:57:40 WARNING mlflow.tracking.fluent: Exception raised while enabling autologging for pyspark: MLflow Spark dataset autologging is not supported on Databricks shared clusters or Databricks serverless clusters.\n",
      "2025/08/08 16:57:40 WARNING mlflow.tracking.fluent: Exception raised while enabling autologging for pyspark.ml: [JVM_ATTRIBUTE_NOT_SUPPORTED] Attribute `sparkContext` is not supported in Spark Connect as it depends on the JVM. If you need to use this attribute, do not use Spark Connect when creating your session. Visit https://spark.apache.org/docs/latest/sql-getting-started.html#starting-point-sparksession for creating regular Spark Session in detail.\n",
      "ðŸ”— View Logged Model at: https://adb-4181970831265458.18.azuredatabricks.net/ml/experiments/3571252969788486/models/m-9f7f58d950764a07b65799c8f40b2ebc?o=4181970831265458\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-de9c4b31-9436-4be9-a101-60d217f02083/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "ðŸ”— View Logged Model at: https://adb-4181970831265458.18.azuredatabricks.net/ml/experiments/3571252969788486/models/m-f613615d6f3a424981824996f896a829?o=4181970831265458\n",
      "2025/08/08 16:58:02 WARNING mlflow.data.spark_delta_utils: Failed to obtain version information for Delta table with name 'pedroz_e2edata_dev.default.iris_data'. Version information may not be included in the dataset source for MLflow Tracking. Exception: [JVM_ATTRIBUTE_NOT_SUPPORTED] Attribute `_jvm` is not supported in Spark Connect as it depends on the JVM. If you need to use this attribute, do not use Spark Connect when creating your session. Visit https://spark.apache.org/docs/latest/sql-getting-started.html#starting-point-sparksession for creating regular Spark Session in detail.\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-de9c4b31-9436-4be9-a101-60d217f02083/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/08/08 16:58:03 WARNING mlflow.data.spark_dataset: Encountered an unexpected exception while computing Spark dataset profile. Exception: [NOT_IMPLEMENTED] rdd is not implemented.\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "\n",
    "# Start a training run\n",
    "with mlflow.start_run() as run:\n",
    "    # Load data from Unity Catalog table\n",
    "    df_iris = spark.table(feature_table_name).toPandas()\n",
    "    features = ['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']\n",
    "    target = 'species'\n",
    "\n",
    "    X = df_iris[features]\n",
    "    y = df_iris[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "    # Train the model\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate and log metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, y_train)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head()\n",
    "    )\n",
    "\n",
    "    # Log input dataset for lineage\n",
    "    data_source = mlflow.data.load_delta(table_name=feature_table_name)\n",
    "    mlflow.log_input(data_source, context=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e85f8e0-b6a0-49da-863c-f090b655a311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'pedroz_e2edata_dev.default.iris_model' already exists. Creating a new version of this model...\n",
      "2025/08/08 16:58:04 WARNING mlflow.tracking._model_registry.fluent: Run with id d6f62b4598754f0392c697d2f8e89e47 has no artifacts at artifact path 'model', registering model based on models:/m-f613615d6f3a424981824996f896a829 instead\n",
      "ðŸ”— Created version '20' of model 'pedroz_e2edata_dev.default.iris_model': https://adb-4181970831265458.18.azuredatabricks.net/explore/data/models/pedroz_e2edata_dev/default/iris_model/version/20?o=4181970831265458\n"
     ]
    }
   ],
   "source": [
    "# Out of all runs in the experiment, only register the run with the best selected metric\n",
    "# Important note: this logic is optional and totally depends on your processes, so feel free to customize it!\n",
    "# If you want, you can simply register the latest run instead, for example. \n",
    "\n",
    "selected_metric = 'test_accuracy'\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id], order_by=[f\"metrics.{selected_metric} DESC\"], max_results=1)\n",
    "best_run_id = runs[0].info.run_id\n",
    "\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "registered_model = mlflow.register_model(model_uri, f\"{catalog_name}.default.{model_name}\")\n",
    "client.set_registered_model_alias(name=registered_model.name, alias=\"challenger\", version=registered_model.version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5753565242613738,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "model-training",
   "widgets": {
    "catalog_name": {
     "currentValue": "pedroz_e2edata_dev",
     "nuid": "c3deff61-8418-4ca2-ae02-acb938772fc8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "pedroz_e2edata_dev",
      "label": null,
      "name": "catalog_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "pedroz_e2edata_dev",
      "label": null,
      "name": "catalog_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
