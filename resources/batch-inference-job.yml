resources:
  jobs:
    batch_inference_job:
      name: "Iris Batch Inference Job - ${var.environment}"
      description: "Job to run batch inference using the iris classification model"
      
      # Email notifications on failure
      email_notifications:
        on_failure:
          - "your.name@address.com"
        no_alert_for_skipped_runs: false
      
      # Job parameters
      parameters:
        - name: "catalog_name"
          default: "${var.catalog_name}"
      
      # If you want to define a shared job cluster for data preprocessing,
      # uncomment the following section - this is an example that works for Azure Databricks
      # job_clusters:
      #   - job_cluster_key: "inference_cluster"
      #     new_cluster:
      #       autoscale:
      #         min_workers: 1
      #         max_workers: 4
      #       spark_version: "15.4.x-scala2.12"
      #       node_type_id: "Standard_D4s_v3"
      #       custom_tags:
      #         Environment: "${var.environment}"
      #         Project: "e2e-data-project"
      #         Purpose: "batch-inference"

      # Job tasks
      tasks:
        - task_key: "batch_inference"
          description: "Run batch inference using the iris classification model"
          
          # Reference the shared job cluster
          job_cluster_key: "inference_cluster"
          
          # Notebook task
          notebook_task:
            notebook_path: "../Notebooks/3_Inference/batch-inference.ipynb"
            base_parameters:
              catalog_name: "{{job.parameters.catalog_name}}"
      
      # Timeout and retry settings
      timeout_seconds: 3600
      max_concurrent_runs: 1 

      # Tags for organization
      tags:
        Environment: "${var.environment}"
        Project: "e2e-data-project" 