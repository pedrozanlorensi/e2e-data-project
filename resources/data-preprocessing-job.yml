resources:
  jobs:
    data_ingestion_job:
      name: "Iris Data Ingestion Job - ${var.environment}"
      description: "Job to ingest iris dataset from sklearn into Unity Catalog"
      
      # Email notifications on failure
      email_notifications:
        on_failure:
          - "your.name@address.com"
        no_alert_for_skipped_runs: false
      
      # Job parameters
      parameters:
        - name: "catalog_name"
          default: "${var.catalog_name}"
      
      # Define a shared job cluster for data preprocessing
      job_clusters:
        - job_cluster_key: "preprocessing_cluster"
          new_cluster:
            autoscale:
              min_workers: 1
              max_workers: 4
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_D4s_v3"
            custom_tags:
              Environment: "${var.environment}"
              Project: "e2e-data-project"
              Purpose: "data-preprocessing"

      # Job tasks
      tasks:
        - task_key: "ingest_data"
          description: "Ingest iris dataset into Unity Catalog"
          
          # Reference the shared job cluster
          job_cluster_key: "preprocessing_cluster"
          
          # Notebook task
          notebook_task:
            notebook_path: "../Notebooks/1_DataPreprocessing/data-ingestion.ipynb"
            base_parameters:
              catalog_name: "{{job.parameters.catalog_name}}"
      
      # Timeout and retry settings
      timeout_seconds: 3600
      max_concurrent_runs: 1
      
      # Tags for organization
      tags:
        Environment: "${var.environment}"
        Project: "e2e-data-project" 